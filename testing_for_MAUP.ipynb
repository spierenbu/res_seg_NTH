{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from scipy.stats import norm \n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import string\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file(\"../data/processed_data/zones_delineation/PC_Leiden.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.area.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_data = pd.read_csv('../data/toy_example/toy_example.csv', names= list(range(0,27)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_data = households_data.applymap(lambda x: x + norm.rvs(loc = 0, scale = 0.5))\n",
    "households_data = households_data.applymap(lambda x: 1 if x>0.5 else 0)\n",
    "#toy_example = toy_example.applymap(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an alphabetical index for the city.\n",
    "list_char=list(string.ascii_uppercase)\n",
    "alphabet=list_char+[x+y for x in list_char for y in list_char]\n",
    "name_columns_1 = alphabet[0:13]\n",
    "# name_columns_2 = [sub + '_2' for sub in alphabet[0:13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_1 = pd.DataFrame(data = [[np.mean(households_data.loc[2*i:2*i+1,2*j:2*j+1].mean().mean()) for i in range(13)] for j in range(13)],\n",
    "                      columns = name_columns_1,\n",
    "                      index = name_columns_1)\n",
    "                      \n",
    "city_2 = pd.DataFrame(data = [[np.mean(households_data.loc[2*i+1:2*i+2,2*j+1:2*j+2].mean().mean()) for i in range(13)] for j in range(13)],\n",
    "                      columns = name_columns_1,\n",
    "                      index = name_columns_1)\n",
    "                      #columns = name_columns_2,\n",
    "                      #index = name_columns_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_res_mix(city_mix):\n",
    "    res_mix = city_mix.T.stack().reset_index()\n",
    "    res_mix = res_mix.rename(columns = {0:'res_mix'})\n",
    "    res_mix['polygon_id'] = res_mix['level_0'] + res_mix['level_1']\n",
    "    res_mix = res_mix.drop(columns = ['level_0','level_1'])\n",
    "    return res_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of a grid.\n",
    "def create_grid_geometry(city_mix, size_cell):\n",
    "\n",
    "    N_rows = len(city_mix)\n",
    "    polygons = []\n",
    "    polygon_id = []\n",
    "\n",
    "    for x in range(N_rows):\n",
    "        for y in range(N_rows):\n",
    "            polygons.append(Polygon([(size_cell*x,size_cell*y), \n",
    "                                    (size_cell*(x+1), size_cell*y), \n",
    "                                    (size_cell*(x+1), size_cell*(y+1)),\n",
    "                                    (size_cell*x, size_cell*(y+1))]))\n",
    "            polygon_id.append(name_columns_1[x] + name_columns_1[y])\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'polygon_id':polygon_id,'geometry':polygons})\n",
    "    \n",
    "    centroids = grid.copy()\n",
    "    centroids['geometry'] = grid.centroid\n",
    "\n",
    "    return grid, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exposure(res_mix, grid):\n",
    "\n",
    "    # Computing the shortest paths from cell to cell.\n",
    "    shortest_paths = pd.DataFrame({'from_polygon':[],'to_polygon':[],'distance':[]})\n",
    "\n",
    "    for i in res_mix['polygon_id']:\n",
    "        shortest_paths_i = pd.DataFrame({'from_polygon':[i]*len(res_mix),\n",
    "                                         'to_polygon':res_mix['polygon_id'],\n",
    "                                         'distance':grid.distance(grid.loc[res_mix['polygon_id'] == i,'geometry'].values[0])})\n",
    "        shortest_paths = pd.concat([shortest_paths,shortest_paths_i], ignore_index=True)\n",
    "    \n",
    "    shortest_paths['weight'] = 1\n",
    "    shortest_paths['weight'] = shortest_paths['weight'].mask(shortest_paths['distance'] > 0,\n",
    "                                                             1/shortest_paths['distance']**2)\n",
    "\n",
    "    exposure = res_mix.merge(shortest_paths[['from_polygon','to_polygon','weight']], \n",
    "                             left_on = 'polygon_id',\n",
    "                             right_on = 'from_polygon')\n",
    "    exposure = exposure.drop(columns = ['from_polygon','polygon_id'])\n",
    "    exposure = exposure.rename(columns = {'to_polygon':'polygon_id'})\n",
    "    exposure['exposure'] = exposure['res_mix']*exposure['weight']\n",
    "    exposure = exposure[['polygon_id','weight','exposure']].groupby(by = 'polygon_id').sum().reset_index()\n",
    "    exposure['exposure'] = exposure['exposure'] / exposure['weight']\n",
    "\n",
    "    exposure = exposure.merge(res_mix, on ='polygon_id')\n",
    "\n",
    "    return exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mix_1 = compute_res_mix(city_1)\n",
    "grid, centroids = create_grid_geometry(city_1, 3)\n",
    "exposure_1 = compute_exposure(res_mix_1, centroids)\n",
    "res_mix_2 = compute_res_mix(city_2)\n",
    "exposure_2 = compute_exposure(res_mix_2, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_1 = exposure_1.add_suffix('_1').rename(columns = {'polygon_id_1':'polygon_id'})\n",
    "exposure_2 = exposure_2.add_suffix('_2').rename(columns = {'polygon_id_2':'polygon_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.merge(exposure_1[['polygon_id','exposure_1','res_mix_1']], on = 'polygon_id')\n",
    "grid = grid.merge(exposure_2[['polygon_id','exposure_2','res_mix_2']], on = 'polygon_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot('res_mix_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot('res_mix_1', vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot('exposure_1', vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot('exposure_2', vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgglomerativeClustering(n_clusters=None,\n",
    "                        connectivity=adjacency_matrix,\n",
    "                        linkage = 'ward').fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains to be done:\n",
    "- Compute regions in the benchmark\n",
    "- Compute regions in the exposure\n",
    "- Compare\n",
    "- Compute the exposure with the fine scale data and compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11eb3bdda620b386ac311b3d07c097973ef5c99cb9184bf1a093190cd8996fdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
